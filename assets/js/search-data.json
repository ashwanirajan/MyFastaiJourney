{
  
    
        "post0": {
            "title": "Here's the App",
            "content": "Gathering Data - Bing API Search . from fastbook import * from utils import * from fastai.vision.widgets import * . To download images with Bing Image Search, sign up at Microsoft for a free account. You will be given a key, which you can copy and enter in a cell as follows (replacing &#39;XXX&#39; with your key and executing it): . key = &#39;27109ffc3c0649ef853678985f164701&#39; . got the key here: https://azure.microsoft.com/en-us/try/cognitive-services/my-apis/?apiSlug=search-api-v7 . from azure.cognitiveservices.search.imagesearch import ImageSearchClient as api from msrest.authentication import CognitiveServicesCredentials as auth . I had made an azure account with a previous microsoft account(from IITG) that I had. It was quite different from what is mentioned in the forum post mentioned by Jeremy. I had three options while making the account, 1. get a 7 day free trial, 2. Get free Azure account and 3. Get paid subscription. I went for 2. get free azure account. It was repeatedly mentioned that I won&#39;t be charged until I upgrade, but when I went to the API page, I see that I have only a 7 day free trial available. I had to give in my Card details though. . def search_images_bing(key, term, min_sz = 128): client = api(&#39;https://api.cognitive.microsoft.com&#39;, auth(key)) return L(client.images.search(query=term,count = 150, min_height = min_sz, min_width = min_sz).value) . L is a class in fastbook. It is fastai&#39;s alternatiive for python lists. . search_images_bing . &lt;function __main__.search_images_bing(key, term, min_sz=128)&gt; . api actually returns 150 items. There are not links. Each item is a dictionary with some keys. One key is &#39;content_url&#39; which is the only thing required for us now. So the L class has an attribute &#39;attrgot&#39; which can be used to get the value of a particular key name from all idems, This is done in the next cell. . results = search_images_bing(key, &#39;soccer ball&#39;) ims = results.attrgot(&#39;content_url&#39;) len(ims) . 150 . Looking at Some Examples . # print(i) . So now ims has a list of URLs for soccer ball images. You can download content from a URL at a particular destination like given in the below slide. . dest = &#39;images/soccerball1.jpg&#39; download_url(ims[0], dest) . Image.open() is from PIL library, which does not need to be called separately because it is one of the dependencies which is called when you call &#39;From fastbook import *&#39; . im = Image.open(dest) im.to_thumb(128,128) . Creating Data Folders . ball_types = &#39;cricket&#39;,&#39;soccer&#39;,&#39;baseball&#39; path = Path(&#39;balls&#39;) ## creates a path in current folder . if not path.exists(): path.mkdir() for o in ball_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o} ball&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . fns = get_image_files(path) ## geting the folder path for all images in balls folder. ## Here all the image paths in all three folders are listed down. fns . (#442) [Path(&#39;balls/baseball/00000000.jpg&#39;),Path(&#39;balls/baseball/00000001.png&#39;),Path(&#39;balls/baseball/00000002.jpg&#39;),Path(&#39;balls/baseball/00000003.png&#39;),Path(&#39;balls/baseball/00000004.png&#39;),Path(&#39;balls/baseball/00000005.jpg&#39;),Path(&#39;balls/baseball/00000006.jpg&#39;),Path(&#39;balls/baseball/00000007.jpg&#39;),Path(&#39;balls/baseball/00000008.jpg&#39;),Path(&#39;balls/baseball/00000009.jpg&#39;)...] . Removing non-image paths . failed = verify_images(fns) ## checks whether that path contains image or not. failed . (#0) [] . path.unlink deletes files. https://stackoverflow.com/questions/42636018/python-difference-between-os-remove-and-os-unlink-and-which-one-to-use/42636082 . .map() calls the function inside the beackets on each element of the object it is attributed to. It is a part of L class. Here, map() calls path.unlink() function on each element of list L=failed. . failed.map(Path.unlink); . From Data to DataLoaders . ImageDataLoaders is a factory method. We have a more flexible way called DataBlock. . balls = DataBlock( blocks=(ImageBlock, CategoryBlock), #independent and dependent variable get_items=get_image_files, # get list of all filenames needed, See 3rd cell in create data folders section to know about function splitter=RandomSplitter(valid_pct=0.2, seed=42), #seed to fix the validation set everytime we run it get_y=parent_label, # how do we label the data.(By the name of parent folder, a pre-defined way in pytorch) item_tfms=Resize(128)) #resize images . The workflow of DataBlock: . get_items is called first. This would list out paths to our entire data. | get_x, get_y is called next. This would define the data and labels | blocks[0], blocks[1] is called. Need to read more on what these mean. | item_tfms are called to include all the required transformations of independent var. &gt; splitter is called which splits the data into training and validation . | A dataloader is called. Dataloader takes a batch(default 64) images so that this batch is run together on the GPU. . | batch_tfms: later | Datablocks return a dataloader a training and validation dataloaders. Dataloaders are a set of 64 images stacked together for one GPU run. Dataloaders.train creates a training batch and dataloaders.valid creates a validation batch. Right now, it seems like a dataloader takes some images and does the augmentation and send it to model. . Data Augmentation . 1. Resizing . item_tfms = Resize(x), changes the size of images to x by x. How? Different Types of Resizes: . Squish: we squish any rectangle to size. Images would be different, bears might look fatter, balls could go oval. | Pad: we resize so that the shorter dimension is a match an use padding with pad_mode. Best method in terms of information retaining, but could lead to procssing of lot of zero-value pixels | Crop: we resize so that the larger dimension is match and crop (randomly on the training set, center crop for the validation set). We lose information | dls = balls.dataloaders(path) ## creating dataloaders. . path # the folder with data is given to dataloaders as input . Path(&#39;balls&#39;) . dls.valid.show_batch(max_n=4, nrows=1) # to see a batch from one validation dataloader . Datablock.new attribute: Create a new datablock which is an exact copy of the previous one, with some changes. I will use new() attribute to create a new datablock but with a different image transform. . balls = balls.new(item_tfms = Resize(100)) dls = balls.dataloaders(path) dls.valid.show_batch() . 2. RandomResizedCrop . min_scale = atlease this much percentage of pixels need to be involved. | unique = True, show_batch for same image. | On the validation set, we center crop the image if it&#39;s ratio isn&#39;t in the range (to the minmum or maximum value) then resize. . balls = balls.new(item_tfms = RandomResizedCrop(128, min_scale = 0.3)) dls = balls.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1, unique = True) . On the train set, random cropping takes place where scale in range (min_scale,1). . dls.train.show_batch(max_n=4, nrows=1, unique = True) . 3. Batch_tfms . item_tfms is done on each individual image and once we set all images to same size, batch transforms can be done. Few points about batch transforms: . done on an entire batch after loading that bach to GPU(loading using dataloaders) | for natural rgb images, there&#39;s a set of augmentations proved to work very well. These have been compiled in the aug_transforms() class. It provides a list of different transformations. | aug_transforms, by default are only applied to training dataloaders. | doc(aug_transforms) . aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode=&#39;bilinear&#39;, pad_mode=&#39;reflection&#39;, align_corners=True, batch=False, min_scale=1.0) . Random flip (or dihedral if flip_vert=True) with p=0.5 is added when do_flip=True. With p_affine we apply a random rotation of max_rotate degrees, a random zoom between min_zoom and max_zoom and a perspective warping of max_warp. With p_lighting we apply a change in brightness and contrast of max_lighting. Custon xtra_tfms can be added. size, mode and pad_mode will be used for the interpolation. max_rotate,max_lighting,max_warp are multiplied by mult so you can more easily increase or decrease augmentation with a single parameter. . p_affine, p_lighting, p could be percentage of images assigned to undergo each kind of augmentation . balls = balls.new(item_tfms = RandomResizedCrop(128, min_scale = 0.3)) ##, batch_tfms = aug_transforms(mult = 2)) can&#39;t run this due to memory error dls = balls.dataloaders(path) dls.train.show_batch( unique = True) #train dataloader is augmented. shft + tab in the #aug_transforms() bracket to see transforms applied. . dls.valid.show_batch( unique = True) ## no augmentations on valid dataloader . Training Your Model . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.588290 | 0.172980 | 0.056818 | 00:07 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . epoch train_loss valid_loss error_rate time . 0 | 0.436581 | 0.120037 | 0.068182 | 00:06 | . 1 | 0.298973 | 0.116487 | 0.034091 | 00:06 | . 2 | 0.220046 | 0.160748 | 0.045455 | 00:06 | . 3 | 0.180335 | 0.170473 | 0.045455 | 00:07 | . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . RuntimeError: DataLoader worker (pid 9945) is killed by signal: Killed. . If you&#39;re using the docker to run the PyTorch program, with high probability, it&#39;s because the shared memory of docker is NOT big enough for running your program in the specified batch size. . The solutions for this circumstance are: . use a smaller batch size to train your model. exit the current docker, and re-run the docker with specified &quot;--shm-size=16g&quot; or bigger shared memory space depending on your machine. Hope this could help those who have the same problem . . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . interp.plot_top_losses(4, nrows=1) . Data Cleaning . Data cleaning normally happens before training. But lately, we can actually use the model outputs like plot_top_losses to do better data cleaning. I personally think that this User Itercative method of data cleaning is only useful in case of small datasets. It will show the images which lead to top losses and we can change the label/delete/keep those images. We normally prefer to train a short baseline model first and then clean the data by looking at the top losses . You can select top losses for validation and train set and decide what you want to clean and also which class you want to clean. From here, we can deal with the high loss data in training sample. Since all other data has lower losses, we can assume that they must be fine too. . doc(plot_top_losses) . cleaner = ImageClassifierCleaner(learn) cleaner . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . /opt/conda/envs/fastai/lib/python3.8/site-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images warnings.warn( . Right now, cleaner object has all the images in Cricket class from the Train data. So cleaner.fns = List of all file paths shown above. and cleaner.delete() and cleaner.change() return all the indices in cleaner.fns which we marked to delete or which we changes the classes. . print(cleaner.delete()) #list of indexes(for cleaner.fns) which were deleted from above print(cleaner.change()) #list of (image indexes from cleaner.fns, correct class) which were changed from one class to another print(cleaner.fns) . (#0) [] (#0) [] (#30) [Path(&#39;balls/baseball/00000119.png&#39;),Path(&#39;balls/baseball/00000138.jpg&#39;),Path(&#39;balls/baseball/00000076.gif&#39;),Path(&#39;balls/baseball/00000101.png&#39;),Path(&#39;balls/baseball/00000066.png&#39;),Path(&#39;balls/baseball/00000030.png&#39;),Path(&#39;balls/baseball/00000065.jpg&#39;),Path(&#39;balls/baseball/00000094.jpg&#39;),Path(&#39;balls/baseball/00000087.jpg&#39;),Path(&#39;balls/baseball/00000099.jpg&#39;)...] . for idx in cleaner.delete(): cleaner.fns[idx].unlink() #delete files which were marked above for idx,cat in cleaner.change(): #cleaner.change() is a list of tuples shutil.move(str(cleaner.fns[idx]), path/cat) # change paths to correct class . Exporting Model to a .pkl File . learn.export() # exporting model in learn object as a pkl file . path1 = Path() # path to the current folder. Path() is used to define a path path1 . Path(&#39;.&#39;) . path1.ls(file_exts = &#39;.pkl&#39;) # list all files with .pkl extension . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path1/&#39;export.pkl&#39;) # load weights . learn_inf.predict(&#39;images/sachin_signed_ball.jpg&#39;) # this image is and out of sample image of cricket #ball signed by sachin. Our Model works!! . (&#39;cricket&#39;, tensor(1), tensor([0.0196, 0.8899, 0.0905])) . (&#39;cricket&#39;, tensor(1), tensor([6.0704e-04, 9.7703e-01, 2.2365e-02])) . The class that our model predicts | That class&#39;s index in learn_inf.dls.vocab | probability/confidence for each class in the order as given in learn_inf.dls.vocab | the inference part of our model(learn_inf) already knows the class names because dataloader is also loaded with our weights in load_learner object. Hence we have the Vocab and the class names. dataloader can be called from load_learner() object. . print(learn_inf.dls) print(learn_inf.dls.vocab) . &lt;fastai.data.core.DataLoaders object at 0x7efcac05b9d0&gt; (#3) [&#39;baseball&#39;,&#39;cricket&#39;,&#39;soccer&#39;] . Creating a Notebook App . Widgets: FileUpload . btn_upload = widgets.FileUpload( accept=&#39;&#39;, # Accepted file extension e.g. &#39;.txt&#39;, &#39;.pdf&#39;, &#39;image/*&#39;, &#39;image/*,.pdf&#39; multiple=False) # True to accept multiple files upload else False btn_upload #placeholder for uploader button . Widgets: Output . img = PILImage.create(btn_upload.data[-1]) # store image that&#39;s uploaded img . out_pl = widgets.Output() out_pl.clear_output() out_pl #Shows no output yet. Once out_pl is filled, then shows value at placeholder . with out_pl: display(img.to_thumb(128,128)) #output is shown from your end, so this code #display is quite a handy function, you can display youtube videos too . Widgets:label, used to show the prediction result . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label(&#39;Here is the ball&#39;) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . Widgets:Run, used to run classifier . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): #function to run on click event on classify button img = PILImage.create(btn_upload.data[-1]) #save image uploaded out_pl.clear_output() #clear the output display with out_pl: display(img.to_thumb(128,128)) # set new output display pred,pred_idx,probs = learn_inf.predict(img) #learn_inf.predict gives 3 values seen above lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; #setting label value btn_run.on_click(on_click_classify) . Bringing all widgets together . btn_upload1 = widgets.FileUpload( accept=&#39;&#39;, # Accepted file extension e.g. &#39;.txt&#39;, &#39;.pdf&#39;, &#39;image/*&#39;, &#39;image/*,.pdf&#39; multiple=False) out_pl1 = widgets.Output() lbl_pred1 = widgets.Label(&#39;Here is the ball&#39;) btn_run1 = widgets.Button(description=&#39;Classify&#39;) btn_run1.on_click(on_click_classify) . This cell below is the essence, here we define what needs to be done in the function, and when is the function triggered. . # 1. store image # 2. clear the previousoutput # 3. show the new output # 4. run the learned inference and get the probability values and prediction # 5. model.predict gives 1.prediction, 2. index of prediction in vocab, 3. probability # of each class in the same order as in vocab. So the 2nd term(index) can be used to find # probability with which the predicted class is supported. def on_click_classify(change): #function to run on click event img = PILImage.create(btn_upload1.data[-1]) #save image uploaded out_pl1.clear_output() #clear the output display with out_pl1: display(img.to_thumb(128,128)) # set new output display pred,pred_idx,probs = learn_inf.predict(img) #learn_inf.predict gives 3 values seen above lbl_pred1.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; #setting label value btn_run1.on_click(on_click_classify) #defining the event and defining the function . VBox([widgets.Label(&#39;Select your ball!&#39;), btn_upload1, btn_run1, out_pl1, lbl_pred1]) .",
            "url": "https://ashwanirajan.github.io/MyFastaiJourney/2020/07/18/Sports-Ball-Classifier-App.html",
            "relUrl": "/2020/07/18/Sports-Ball-Classifier-App.html",
            "date": " • Jul 18, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ashwanirajan.github.io/MyFastaiJourney/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ashwanirajan.github.io/MyFastaiJourney/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}